{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGFB_ImGYBVz",
        "outputId": "a5d4a619-d0a1-4366-fbc2-16e00f67933b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Question  \\\n",
            "0  What approach did the political parties in Pak...   \n",
            "1  What is the US government's stance towards Pak...   \n",
            "2  What is the root cause of the Muslims' resentm...   \n",
            "3  What was the purpose of the Charter of Democracy?   \n",
            "4  How did Nawaz Sharif react to a few members of...   \n",
            "\n",
            "                                              Answer  \n",
            "0  They aimed to bring peace through dialogue rat...  \n",
            "1  The US government has decried the peace accord...  \n",
            "2  The root causes are past and present discrimin...  \n",
            "3  Nawaz Sharif and late Benazir Bhutto were goin...  \n",
            "4  Nawaz Sharif thought for a long time and then ...  \n",
            "Question    0\n",
            "Answer      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/qa_pairs.csv')\n",
        "\n",
        "# Inspect data\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values if any\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert to JSON-like format for instruction tuning\n",
        "df['data'] = df.apply(lambda row: {'instruction': 'Answer the following question based on your knowledge.',\n",
        "                                   'question': row['Question'],\n",
        "                                   'answer': row['Answer']}, axis=1)\n",
        "\n",
        "# Save to a new JSON file\n",
        "df['data'].to_json('formatted_dataset.json', orient='records')\n",
        "\n",
        "# Split data into train, validate, and test sets\n",
        "train, validate, test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                 [int(.8*len(df)), int(.9*len(df))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xGSmxF3Ucygt",
        "outputId": "6707d4d5-9173-4d42-82c4-0c98516e4207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "291   What is the Deoband seminary's view on terrori...   \n",
              "3056  What were the two instances where the Pakistan...   \n",
              "2093  What are some reasons for corruption in the po...   \n",
              "432   What are the potential consequences of an Isra...   \n",
              "479   What is the author's concern about the loss of...   \n",
              "...                                                 ...   \n",
              "2220              What was the trauma of the Partition?   \n",
              "2979  What did the Prime Minister recently commit to...   \n",
              "2105  What is the significance of the Sachar Report ...   \n",
              "133   What is the proposed solution to dealing with ...   \n",
              "1140         Why was Rosa Parks arrested in Montgomery?   \n",
              "\n",
              "                                                 Answer  \\\n",
              "291   The prestigious seminary at Deoband has ruled ...   \n",
              "3056  The Pakistani army was tested twice within a f...   \n",
              "2093  Low pay and insufficient compensation packages...   \n",
              "432   The fallout could be radioactive chaos and the...   \n",
              "479   The author is concerned that the loss of the s...   \n",
              "...                                                 ...   \n",
              "2220  The refugees on both sides received a poor rec...   \n",
              "2979  The PM recently committed to fighting corrupti...   \n",
              "2105  The Sachar Report is a high powered report ini...   \n",
              "133   Catch the speculators and deal with them as th...   \n",
              "1140  She refused to get up of her seat on a public ...   \n",
              "\n",
              "                                                   data  \n",
              "291   {'instruction': 'Answer the following question...  \n",
              "3056  {'instruction': 'Answer the following question...  \n",
              "2093  {'instruction': 'Answer the following question...  \n",
              "432   {'instruction': 'Answer the following question...  \n",
              "479   {'instruction': 'Answer the following question...  \n",
              "...                                                 ...  \n",
              "2220  {'instruction': 'Answer the following question...  \n",
              "2979  {'instruction': 'Answer the following question...  \n",
              "2105  {'instruction': 'Answer the following question...  \n",
              "133   {'instruction': 'Answer the following question...  \n",
              "1140  {'instruction': 'Answer the following question...  \n",
              "\n",
              "[2716 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-778c7397-7c47-4bd3-baa4-074e888b3b60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>What is the Deoband seminary's view on terrori...</td>\n",
              "      <td>The prestigious seminary at Deoband has ruled ...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3056</th>\n",
              "      <td>What were the two instances where the Pakistan...</td>\n",
              "      <td>The Pakistani army was tested twice within a f...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2093</th>\n",
              "      <td>What are some reasons for corruption in the po...</td>\n",
              "      <td>Low pay and insufficient compensation packages...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>What are the potential consequences of an Isra...</td>\n",
              "      <td>The fallout could be radioactive chaos and the...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>What is the author's concern about the loss of...</td>\n",
              "      <td>The author is concerned that the loss of the s...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>What was the trauma of the Partition?</td>\n",
              "      <td>The refugees on both sides received a poor rec...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2979</th>\n",
              "      <td>What did the Prime Minister recently commit to...</td>\n",
              "      <td>The PM recently committed to fighting corrupti...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>What is the significance of the Sachar Report ...</td>\n",
              "      <td>The Sachar Report is a high powered report ini...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>What is the proposed solution to dealing with ...</td>\n",
              "      <td>Catch the speculators and deal with them as th...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>Why was Rosa Parks arrested in Montgomery?</td>\n",
              "      <td>She refused to get up of her seat on a public ...</td>\n",
              "      <td>{'instruction': 'Answer the following question...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2716 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778c7397-7c47-4bd3-baa4-074e888b3b60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-778c7397-7c47-4bd3-baa4-074e888b3b60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-778c7397-7c47-4bd3-baa4-074e888b3b60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71278d46-b103-4c11-937a-85d65d2bc7f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71278d46-b103-4c11-937a-85d65d2bc7f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71278d46-b103-4c11-937a-85d65d2bc7f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c4ee39a2-3237-4824-a094-4fdb3f7c1c0e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c4ee39a2-3237-4824-a094-4fdb3f7c1c0e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 2716,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2716,\n        \"samples\": [\n          \"What is the Bhurban Declaration?\",\n          \"What is the cost of the ongoing conflicts in Iraq and Afghanistan?\",\n          \"What historic event is seen as a defining moment for South Mumbai's election in 1967?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2716,\n        \"samples\": [\n          \"The Bhurban Declaration was widely acclaimed for its support of the restoration of the judiciary and the victory of democracy.\",\n          \"According to Nobel Prize-winning economist Joseph E Stiglitz and co-author Linda J Bilmes, the total cost of the Iraq war, including care of injured soldiers for the rest of their lives, could cost two trillion dollars when all is said and done.\",\n          \"The election of South Mumbai in 1967 is seen as a defining moment when the socialist Fernandes defeated the city's then uncrowned king Patil.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z0r9iplreI0c"
      },
      "outputs": [],
      "source": [
        "# Function to save checkpoints\n",
        "def save_checkpoint(model, optimizer, step, path=\"checkpoints\"):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    checkpoint_path = os.path.join(path, f\"checkpoint_{step}.pt\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Checkpoint saved to {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t6Xdp8_Hdut5"
      },
      "outputs": [],
      "source": [
        "def encode_data(tokenizer, questions, answers, max_length=128):\n",
        "    # Check if the tokenizer has a padding token, set if not\n",
        "    if tokenizer.pad_token is None:\n",
        "        print(\"No padding token found. Using `eos_token` as `pad_token`.\")\n",
        "        tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
        "\n",
        "    return tokenizer(questions, answers, truncation=True, padding='max_length', max_length=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByjxoL33flX6"
      },
      "source": [
        "#**GPT2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nLxe6iitd0eD"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQR642dUj72",
        "outputId": "68e848e9-8b5d-4d3a-edaf-ba054ee11f12"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okV7-ddId15z",
        "outputId": "59201fe4-5866-4d37-a9cc-b898f0e1ad25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to('cpu')  # Ensure model is on GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LSIHIWfLd3zE"
      },
      "outputs": [],
      "source": [
        "# Check and set padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cJjqgnm9d51e"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PAEArOO8d7fY"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize data\n",
        "def encode_data(tokenizer, questions, answers):\n",
        "    return tokenizer(questions, answers, truncation=True, padding='max_length', max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgyRSsjqd9RG",
        "outputId": "5c2b7cae-d82e-42ad-db9a-640709cef6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "# Prepare datasets\n",
        "train_encodings = encode_data(tokenizer, train['Question'].tolist(), train['Answer'].tolist())\n",
        "train_dataset = QADataset(train_encodings)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Gxv3MwGDeCln"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WonuGondurZ",
        "outputId": "723f7685-1ac9-4012-cb3b-0c80487046df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1, Loss 7.071007251739502\n",
            "Step 2, Loss 4.424864768981934\n",
            "Step 3, Loss 2.5355098247528076\n",
            "Step 4, Loss 1.8143633604049683\n",
            "Step 5, Loss 1.3688706159591675\n",
            "Step 6, Loss 1.1164625883102417\n",
            "Step 7, Loss 2.6985533237457275\n",
            "Step 8, Loss 1.406386137008667\n",
            "Step 9, Loss 2.0608749389648438\n",
            "Step 10, Loss 1.488075852394104\n",
            "Step 11, Loss 1.4531152248382568\n",
            "Step 12, Loss 1.46669340133667\n",
            "Step 13, Loss 1.1481595039367676\n",
            "Step 14, Loss 1.0777345895767212\n",
            "Step 15, Loss 1.6924307346343994\n",
            "Step 16, Loss 2.0468809604644775\n",
            "Step 17, Loss 1.3495584726333618\n",
            "Step 19, Loss 1.3800315856933594\n",
            "Step 20, Loss 1.3761084079742432\n",
            "Step 21, Loss 1.4692143201828003\n",
            "Step 22, Loss 1.5447944402694702\n",
            "Step 23, Loss 1.5103892087936401\n",
            "Step 24, Loss 1.6343141794204712\n",
            "Step 25, Loss 1.4366356134414673\n",
            "Step 26, Loss 1.0745160579681396\n",
            "Step 27, Loss 1.1464712619781494\n",
            "Step 28, Loss 1.3857817649841309\n",
            "Step 29, Loss 1.8218520879745483\n",
            "Step 30, Loss 1.3089367151260376\n",
            "Step 31, Loss 1.0369764566421509\n",
            "Step 32, Loss 1.455783486366272\n",
            "Step 33, Loss 1.7804951667785645\n",
            "Step 34, Loss 1.555296540260315\n",
            "Step 35, Loss 1.9275251626968384\n",
            "Step 36, Loss 1.0685455799102783\n",
            "Step 37, Loss 1.5156968832015991\n",
            "Step 38, Loss 1.1839845180511475\n",
            "Step 39, Loss 1.2843916416168213\n",
            "Step 40, Loss 1.5586227178573608\n",
            "Step 41, Loss 1.9579720497131348\n",
            "Step 42, Loss 1.269474744796753\n",
            "Step 43, Loss 1.74214506149292\n",
            "Step 44, Loss 1.6317180395126343\n",
            "Step 45, Loss 1.628658413887024\n",
            "Step 46, Loss 1.8288925886154175\n",
            "Step 47, Loss 1.4596737623214722\n",
            "Step 48, Loss 0.8684852719306946\n",
            "Step 49, Loss 0.8807277083396912\n",
            "Step 50, Loss 1.2199870347976685\n",
            "Step 51, Loss 1.3584777116775513\n",
            "Step 52, Loss 1.4350008964538574\n",
            "Step 53, Loss 1.4052116870880127\n",
            "Step 54, Loss 1.5562421083450317\n",
            "Step 55, Loss 1.6534262895584106\n",
            "Step 56, Loss 1.5454621315002441\n",
            "Step 57, Loss 0.9594997763633728\n",
            "Step 58, Loss 1.3709278106689453\n",
            "Step 59, Loss 1.152429223060608\n",
            "Step 60, Loss 1.138084888458252\n",
            "Step 61, Loss 1.3720039129257202\n",
            "Step 62, Loss 1.2453210353851318\n",
            "Step 63, Loss 1.328952431678772\n",
            "Step 64, Loss 1.3447976112365723\n",
            "Step 65, Loss 1.3814157247543335\n",
            "Step 66, Loss 2.0384721755981445\n",
            "Step 67, Loss 1.145331859588623\n",
            "Step 68, Loss 1.0151114463806152\n",
            "Step 69, Loss 0.8814130425453186\n",
            "Step 70, Loss 1.0656523704528809\n",
            "Step 71, Loss 1.4718071222305298\n",
            "Step 72, Loss 1.7868343591690063\n",
            "Step 73, Loss 1.726415753364563\n",
            "Step 74, Loss 1.077964186668396\n",
            "Step 75, Loss 1.5565118789672852\n",
            "Step 76, Loss 1.1079562902450562\n",
            "Step 77, Loss 1.1188267469406128\n",
            "Step 78, Loss 0.978654146194458\n",
            "Step 79, Loss 1.129237413406372\n",
            "Step 80, Loss 1.322725772857666\n",
            "Step 81, Loss 1.8935768604278564\n",
            "Step 82, Loss 1.1117907762527466\n",
            "Step 83, Loss 1.2606594562530518\n",
            "Step 84, Loss 1.6659828424453735\n",
            "Step 85, Loss 1.1923975944519043\n",
            "Step 86, Loss 1.3832056522369385\n",
            "Step 87, Loss 1.4577070474624634\n",
            "Step 88, Loss 1.3809754848480225\n",
            "Step 89, Loss 1.506278395652771\n",
            "Step 90, Loss 1.199346661567688\n",
            "Step 91, Loss 1.0208017826080322\n",
            "Step 92, Loss 1.258628249168396\n",
            "Step 93, Loss 1.4223531484603882\n",
            "Step 94, Loss 1.0291104316711426\n",
            "Step 95, Loss 1.4421906471252441\n",
            "Step 96, Loss 1.186511516571045\n",
            "Step 97, Loss 1.17632257938385\n",
            "Step 98, Loss 1.3695225715637207\n",
            "Step 99, Loss 1.300973653793335\n",
            "Step 100, Loss 1.1190508604049683\n",
            "Step 101, Loss 0.7056773900985718\n",
            "Step 102, Loss 1.5124753713607788\n",
            "Step 103, Loss 1.4750429391860962\n",
            "Step 104, Loss 1.288520336151123\n",
            "Step 105, Loss 1.1111350059509277\n",
            "Step 106, Loss 1.7951326370239258\n",
            "Step 107, Loss 1.5246902704238892\n",
            "Step 108, Loss 0.8234857320785522\n",
            "Step 109, Loss 1.4237966537475586\n",
            "Step 110, Loss 1.3058995008468628\n",
            "Step 111, Loss 1.3789160251617432\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "step = 0\n",
        "for epoch in range(3):  # number of epochs\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to('cpu')\n",
        "        attention_mask = batch['attention_mask'].to('cpu')\n",
        "        labels = input_ids\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
        "\n",
        "        if (step + 1) % 1131 == 0:\n",
        "            save_checkpoint(model, optimizer, step+1)\n",
        "\n",
        "        step += 1\n",
        "        print(f\"Step {step}, Loss {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Prepare validation and test datasets\n",
        "validate_encodings = encode_data(tokenizer, validate['Question'].tolist(), validate['Answer'].tolist())\n",
        "validate_dataset = QADataset(validate_encodings)\n",
        "validate_loader = DataLoader(validate_dataset, batch_size=4, shuffle=False)  # No need to shuffle\n",
        "\n",
        "test_encodings = encode_data(tokenizer, test['Question'].tolist(), test['Answer'].tolist())\n",
        "test_dataset = QADataset(test_encodings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)  # No need to shuffle\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to('cpu')\n",
        "            attention_mask = batch['attention_mask'].to('cpu')\n",
        "            labels = input_ids\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1).tolist()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds, val_labels = evaluate_model(model, validate_loader)\n",
        "val_precision = precision_score(val_labels, val_preds, average='macro')\n",
        "val_recall = recall_score(val_labels, val_preds, average='macro')\n",
        "val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "\n",
        "print(\"Validation Precision:\", val_precision)\n",
        "print(\"Validation Recall:\", val_recall)\n",
        "print(\"Validation F1-score:\", val_f1)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_preds, test_labels = evaluate_model(model, test_loader)\n",
        "test_precision = precision_score(test_labels, test_preds, average='macro')\n",
        "test_recall = recall_score(test_labels, test_preds, average='macro')\n",
        "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "print(\"Test Precision:\", test_precision)\n",
        "print(\"Test Recall:\", test_recall)\n",
        "print(\"Test F1-score:\", test_f1)\n"
      ],
      "metadata": {
        "id": "p4qymBpheNnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}