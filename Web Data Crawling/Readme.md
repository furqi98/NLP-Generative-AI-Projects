
# 🕷️ Web Data Crawling - Assignment 1  

## 📌 Overview  
This project involves developing a **web crawler** to extract textual data from **Pakistani-origin news websites**, specifically **Dawn.com**. The goal is to **scrape, clean, and store structured data** from online sources using Python-based web scraping libraries.  

## 🚀 Features  
✅ **Web Crawling**: Extract news headlines, descriptions, publication dates, and images.  
✅ **Text Cleaning**: Remove HTML tags, punctuation, and extra spaces for clean text.  
✅ **Data Storage**: Store extracted content in a **CSV file** for further analysis.  
✅ **Colab Notebook**: A step-by-step **Google Colab Notebook** demonstrating the entire crawling process.  

## 🛠️ Technologies Used  
- **Python**  
- **BeautifulSoup** – For web scraping  
- **Requests** – For making HTTP requests  
- **CSV Handling** – To store structured data  

## 📥 Installation & Setup  

1️⃣ Install Jupyter Notebook (if not installed)

bash
Copy
Edit
pip install notebook
2️⃣ Launch Jupyter Notebook

bash
Copy
Edit
jupyter notebook
3️⃣ Open the .ipynb file and run the cells in sequence.
```


## 📊 Data Collected  
✅ **2GB+ of text data** from multiple news articles  
✅ Stored in **CSV format** for further processing  
✅ Covers **headlines, descriptions, dates, and URLs**  

 

